{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5a40d38",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-20T20:45:38.347775Z",
     "iopub.status.busy": "2025-07-20T20:45:38.347548Z",
     "iopub.status.idle": "2025-07-20T20:45:57.406788Z",
     "shell.execute_reply": "2025-07-20T20:45:57.405931Z"
    },
    "papermill": {
     "duration": 19.064886,
     "end_time": "2025-07-20T20:45:57.408173",
     "exception": false,
     "start_time": "2025-07-20T20:45:38.343287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "943c0b81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T20:45:57.415162Z",
     "iopub.status.busy": "2025-07-20T20:45:57.414451Z",
     "iopub.status.idle": "2025-07-20T20:45:57.418964Z",
     "shell.execute_reply": "2025-07-20T20:45:57.418240Z"
    },
    "papermill": {
     "duration": 0.008817,
     "end_time": "2025-07-20T20:45:57.420029",
     "exception": false,
     "start_time": "2025-07-20T20:45:57.411212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a1f957a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T20:45:57.425737Z",
     "iopub.status.busy": "2025-07-20T20:45:57.425530Z",
     "iopub.status.idle": "2025-07-20T20:45:57.490550Z",
     "shell.execute_reply": "2025-07-20T20:45:57.490026Z"
    },
    "papermill": {
     "duration": 0.069142,
     "end_time": "2025-07-20T20:45:57.491692",
     "exception": false,
     "start_time": "2025-07-20T20:45:57.422550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dir = '/kaggle/input/sheep-classification-challenge-2025/Sheep Classification Images/train'\n",
    "test_dir = '/kaggle/input/sheep-classification-challenge-2025/Sheep Classification Images/test'\n",
    "train_labels_csv = '/kaggle/input/sheep-classification-challenge-2025/Sheep Classification Images/train_labels.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_labels_csv)\n",
    "\n",
    "corrections = { # Corrected label errors in the training set\n",
    "    '9ed08b0c.jpg': 'Naeimi',\n",
    "    '8939e4f2.jpg': 'Naeimi',\n",
    "    '94c8adc1.jpg': 'Sawakni',\n",
    "    '21dfb4da.jpg': 'Harri',\n",
    "    '9d221581.jpg': 'Sawakni',\n",
    "    'c238564e.jpg': 'Naeimi',\n",
    "    '67b098e7.jpg': 'Harri',\n",
    "    '719c75d0.jpg': 'Naeimi',\n",
    "    'c9204f2e.jpg': 'Naeimi',\n",
    "    '2b934ba9.jpg': 'Naeimi',\n",
    "    'f6c9933f.jpg': 'Harri',\n",
    "    '25d3aa13.jpg': 'Sawakni'\n",
    "}\n",
    "\n",
    "for fname, correct_label in corrections.items():\n",
    "    train_df.loc[train_df['filename'] == fname, 'label'] = correct_label\n",
    "    \n",
    "train_df['filename'] = train_df['filename'].apply(lambda x: os.path.join(train_dir, x))\n",
    "\n",
    "classes = sorted(train_df['label'].unique())\n",
    "class_to_idx = {c:i for i,c in enumerate(classes)}\n",
    "idx_to_class = {i:c for c,i in class_to_idx.items()}\n",
    "train_df['label_idx'] = train_df['label'].map(class_to_idx)\n",
    "\n",
    "test_filenames = sorted(os.listdir(test_dir))\n",
    "test_df = pd.DataFrame({'filename': [os.path.join(test_dir, f) for f in test_filenames]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b52d09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T20:45:57.497365Z",
     "iopub.status.busy": "2025-07-20T20:45:57.497164Z",
     "iopub.status.idle": "2025-07-20T20:45:57.591714Z",
     "shell.execute_reply": "2025-07-20T20:45:57.590924Z"
    },
    "papermill": {
     "duration": 0.098729,
     "end_time": "2025-07-20T20:45:57.592872",
     "exception": false,
     "start_time": "2025-07-20T20:45:57.494143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'n_classes': len(classes),\n",
    "    'n_folds': 3,\n",
    "    'n_epochs': 3,\n",
    "    'batch_size': 32,\n",
    "    'lr': 5e-4,\n",
    "    'seed': 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59d10ee",
   "metadata": {
    "papermill": {
     "duration": 0.002685,
     "end_time": "2025-07-20T20:45:57.598489",
     "exception": false,
     "start_time": "2025-07-20T20:45:57.595804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Custom Dataset Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72c7538c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T20:45:57.604957Z",
     "iopub.status.busy": "2025-07-20T20:45:57.604697Z",
     "iopub.status.idle": "2025-07-20T20:45:57.609606Z",
     "shell.execute_reply": "2025-07-20T20:45:57.609023Z"
    },
    "papermill": {
     "duration": 0.009214,
     "end_time": "2025-07-20T20:45:57.610561",
     "exception": false,
     "start_time": "2025-07-20T20:45:57.601347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SheepDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.is_train = 'label' in self.df.columns\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx, 0]\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform: \n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.is_train:\n",
    "            return img, self.df.iloc[idx, 2] # image, label_idx\n",
    "        return img, os.path.basename(img_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c8e79c",
   "metadata": {
    "papermill": {
     "duration": 0.002224,
     "end_time": "2025-07-20T20:45:57.615097",
     "exception": false,
     "start_time": "2025-07-20T20:45:57.612873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Instantiation for Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fbc6f4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T20:45:57.620785Z",
     "iopub.status.busy": "2025-07-20T20:45:57.620576Z",
     "iopub.status.idle": "2025-07-20T20:45:57.626196Z",
     "shell.execute_reply": "2025-07-20T20:45:57.625697Z"
    },
    "papermill": {
     "duration": 0.009919,
     "end_time": "2025-07-20T20:45:57.627391",
     "exception": false,
     "start_time": "2025-07-20T20:45:57.617472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(model_name):\n",
    "    model = None\n",
    "    \n",
    "    if model_name == 'convnext_tiny':\n",
    "        model = models.convnext_tiny(weights=models.ConvNeXt_Tiny_Weights.DEFAULT)\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in model.features[7].parameters():\n",
    "            p.requires_grad = True\n",
    "        for p in model.classifier.parameters():\n",
    "            p.requires_grad = True\n",
    "            \n",
    "        in_features = model.classifier[2].in_features\n",
    "        model.classifier[2] = nn.Linear(in_features, config['n_classes'])\n",
    "        \n",
    "    elif model_name == 'maxvit_t':\n",
    "        model = models.maxvit_t(weights=models.MaxVit_T_Weights.DEFAULT)\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in model.classifier.parameters():\n",
    "            p.requires_grad = True\n",
    "        for p in model.blocks[2].parameters():\n",
    "            p.requires_grad = True\n",
    "        for p in model.blocks[3].parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        in_features = model.classifier[5].in_features\n",
    "        model.classifier[5] = nn.Linear(in_features, config['n_classes'])\n",
    "\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2217267",
   "metadata": {
    "papermill": {
     "duration": 0.002462,
     "end_time": "2025-07-20T20:45:57.632431",
     "exception": false,
     "start_time": "2025-07-20T20:45:57.629969",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training and Evaluation with Stratified Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54a800b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T20:45:57.639128Z",
     "iopub.status.busy": "2025-07-20T20:45:57.638899Z",
     "iopub.status.idle": "2025-07-20T20:45:57.653988Z",
     "shell.execute_reply": "2025-07-20T20:45:57.653354Z"
    },
    "papermill": {
     "duration": 0.019916,
     "end_time": "2025-07-20T20:45:57.655113",
     "exception": false,
     "start_time": "2025-07-20T20:45:57.635197",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, scheduler, n_epochs, device):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "                y_true.append(labels.cpu())\n",
    "                y_pred.append(torch.argmax(outputs, dim=1).cpu())\n",
    "\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        y_true = torch.cat(y_true).numpy()\n",
    "        y_pred = torch.cat(y_pred).numpy()\n",
    "        f1 = f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val F1: {f1:.4f}\")\n",
    "        \n",
    "    \n",
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    logits = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            logits.append(outputs.cpu())\n",
    "\n",
    "    return torch.cat(logits, dim=0)\n",
    "    \n",
    "\n",
    "def run_cv(\n",
    "    model_name,\n",
    "    train_df,\n",
    "    test_loader,\n",
    "    train_transform,\n",
    "    val_transform,\n",
    "    n_folds = config['n_folds'],\n",
    "    batch_size = config['batch_size'],\n",
    "    n_epochs = config['n_epochs'],\n",
    "    lr = config['lr'],\n",
    "    device = config['device'],\n",
    "    seed = config['seed'],\n",
    "):\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "    all_val_logits = torch.zeros((len(train_df), config['n_classes']))\n",
    "    test_logits_per_fold = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(\n",
    "        skf.split(train_df, train_df[\"label_idx\"]), start=1\n",
    "    ):\n",
    "        print(f\"\\nFold {fold}/{n_folds}\")\n",
    "\n",
    "        df_tr = train_df.iloc[train_idx]\n",
    "        df_va = train_df.iloc[val_idx]\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            SheepDataset(df_tr, train_transform),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            SheepDataset(df_va, val_transform),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        # instantiate model, criterion, optimizer, scheduler\n",
    "        model = create_model(model_name).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, T_max=n_epochs, eta_min=1e-6\n",
    "        )\n",
    "\n",
    "        # train + validate\n",
    "        train(\n",
    "            model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            n_epochs,\n",
    "            device,\n",
    "        )\n",
    "        \n",
    "        # Store validation logits for current fold\n",
    "        all_val_logits[val_idx] = evaluate(model, val_loader, device)\n",
    "\n",
    "        # Generate test logits for current fold\n",
    "        model.eval()\n",
    "        fold_test_logits = []  # Per-batch logits for this fold\n",
    "        with torch.no_grad():\n",
    "            for imgs, _ in test_loader:\n",
    "                imgs = imgs.to(device)\n",
    "                outputs = model(imgs)\n",
    "                fold_test_logits.append(outputs.cpu())\n",
    "                \n",
    "        # Store complete test logits for this fold\n",
    "        test_logits_per_fold.append(torch.cat(fold_test_logits, dim=0))\n",
    "        \n",
    "    test_mean_logits = torch.stack(test_logits_per_fold).mean(dim=0)\n",
    "    \n",
    "    # Compute overall CV F1\n",
    "    all_val_pred = torch.argmax(all_val_logits, dim=1).numpy()\n",
    "    overall_f1 = f1_score(train_df['label_idx'].values, all_val_pred, average='macro')\n",
    "    print(f\"\\nOverall CV F1: {overall_f1:.4f}\")\n",
    "\n",
    "    return all_val_logits, test_mean_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b315d75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T20:45:57.661033Z",
     "iopub.status.busy": "2025-07-20T20:45:57.660833Z",
     "iopub.status.idle": "2025-07-20T20:49:19.074438Z",
     "shell.execute_reply": "2025-07-20T20:49:19.073709Z"
    },
    "papermill": {
     "duration": 201.417919,
     "end_time": "2025-07-20T20:49:19.075812",
     "exception": false,
     "start_time": "2025-07-20T20:45:57.657893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "convnext_tiny\n",
      "\n",
      "Fold 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/convnext_tiny-983f1562.pth\" to /root/.cache/torch/hub/checkpoints/convnext_tiny-983f1562.pth\n",
      "100%|██████████| 109M/109M [00:00<00:00, 210MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 0.8852 | Val Loss: 0.3192 | Val F1: 0.8519\n",
      "Epoch 02 | Train Loss: 0.1180 | Val Loss: 0.2218 | Val F1: 0.8804\n",
      "Epoch 03 | Train Loss: 0.0497 | Val Loss: 0.2033 | Val F1: 0.9133\n",
      "\n",
      "Fold 2/3\n",
      "Epoch 01 | Train Loss: 0.9294 | Val Loss: 0.2632 | Val F1: 0.9390\n",
      "Epoch 02 | Train Loss: 0.1257 | Val Loss: 0.1777 | Val F1: 0.9348\n",
      "Epoch 03 | Train Loss: 0.0541 | Val Loss: 0.1364 | Val F1: 0.9432\n",
      "\n",
      "Fold 3/3\n",
      "Epoch 01 | Train Loss: 0.9239 | Val Loss: 0.2400 | Val F1: 0.9002\n",
      "Epoch 02 | Train Loss: 0.1460 | Val Loss: 0.1204 | Val F1: 0.9308\n",
      "Epoch 03 | Train Loss: 0.0368 | Val Loss: 0.1159 | Val F1: 0.9295\n",
      "\n",
      "Overall CV F1: 0.9294\n",
      "\n",
      "maxvit_t\n",
      "\n",
      "Fold 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/maxvit_t-bc5ab103.pth\" to /root/.cache/torch/hub/checkpoints/maxvit_t-bc5ab103.pth\n",
      "100%|██████████| 119M/119M [00:00<00:00, 190MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 1.1138 | Val Loss: 0.3680 | Val F1: 0.8970\n",
      "Epoch 02 | Train Loss: 0.2518 | Val Loss: 0.1630 | Val F1: 0.9526\n",
      "Epoch 03 | Train Loss: 0.0867 | Val Loss: 0.1082 | Val F1: 0.9670\n",
      "\n",
      "Fold 2/3\n",
      "Epoch 01 | Train Loss: 0.9798 | Val Loss: 0.4513 | Val F1: 0.8345\n",
      "Epoch 02 | Train Loss: 0.1639 | Val Loss: 0.3186 | Val F1: 0.8930\n",
      "Epoch 03 | Train Loss: 0.0434 | Val Loss: 0.2117 | Val F1: 0.9332\n",
      "\n",
      "Fold 3/3\n",
      "Epoch 01 | Train Loss: 0.9707 | Val Loss: 0.2906 | Val F1: 0.9096\n",
      "Epoch 02 | Train Loss: 0.1476 | Val Loss: 0.1471 | Val F1: 0.9415\n",
      "Epoch 03 | Train Loss: 0.0373 | Val Loss: 0.1815 | Val F1: 0.9257\n",
      "\n",
      "Overall CV F1: 0.9438\n"
     ]
    }
   ],
   "source": [
    "val_logits_dict = {}\n",
    "test_logits_dict = {}\n",
    "\n",
    "model_names = ['convnext_tiny', 'maxvit_t']\n",
    "for i, model_name in enumerate(model_names):\n",
    "    print(f'\\n{model_name}')\n",
    "    \n",
    "    seed = config['seed'] + i\n",
    "    seed_everything(seed)\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        transforms.RandomErasing(p=0.1, scale=(0.1, 0.2), ratio=(0.2, 3)),\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    test_dataset = SheepDataset(test_df, val_transform)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "    \n",
    "    val_logits, test_logits = run_cv(model_name, train_df, test_loader, train_transform, val_transform, seed=seed)\n",
    "    \n",
    "    val_logits_dict[model_name] = val_logits\n",
    "    test_logits_dict[model_name] = test_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c27886",
   "metadata": {
    "papermill": {
     "duration": 0.004122,
     "end_time": "2025-07-20T20:49:19.084486",
     "exception": false,
     "start_time": "2025-07-20T20:49:19.080364",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Optimal Weighted Ensemble Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09c69829",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T20:49:19.093883Z",
     "iopub.status.busy": "2025-07-20T20:49:19.093652Z",
     "iopub.status.idle": "2025-07-20T20:49:19.227659Z",
     "shell.execute_reply": "2025-07-20T20:49:19.226838Z"
    },
    "papermill": {
     "duration": 0.140255,
     "end_time": "2025-07-20T20:49:19.228834",
     "exception": false,
     "start_time": "2025-07-20T20:49:19.088579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.94380 | Weight: 0.0\n",
      "F1 Score: 0.94541 | Weight: 0.03\n",
      "F1 Score: 0.94637 | Weight: 0.06\n",
      "F1 Score: 0.94834 | Weight: 0.09\n",
      "F1 Score: 0.95102 | Weight: 0.2\n",
      "F1 Score: 0.95245 | Weight: 0.31\n",
      "F1 Score: 0.95512 | Weight: 0.32\n",
      "F1 Score: 0.95787 | Weight: 0.33\n",
      "F1 Score: 0.95882 | Weight: 0.34\n",
      "F1 Score: 0.96109 | Weight: 0.48\n",
      "Best Score: 0.96109 | Best Weight: 0.48\n"
     ]
    }
   ],
   "source": [
    "best_weight = 0.0\n",
    "best_score = 0.0\n",
    "for w in np.linspace(0, 1, 101):\n",
    "    ensemble = w * val_logits_dict[model_names[0]] + (1 - w) * val_logits_dict[model_names[1]]\n",
    "    ensemble = torch.argmax(ensemble, dim=1)\n",
    "    score = f1_score(train_df['label_idx'].values, ensemble, average=\"macro\")\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_weight = w\n",
    "        print(f'F1 Score: {best_score:.5f} | Weight: {best_weight}')\n",
    "\n",
    "print(f'Best Score: {best_score:.5f} | Best Weight: {best_weight}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47184310",
   "metadata": {
    "papermill": {
     "duration": 0.00401,
     "end_time": "2025-07-20T20:49:19.237749",
     "exception": false,
     "start_time": "2025-07-20T20:49:19.233739",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Submission from Best-Weighted Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63918325",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-20T20:49:19.246979Z",
     "iopub.status.busy": "2025-07-20T20:49:19.246522Z",
     "iopub.status.idle": "2025-07-20T20:49:19.270319Z",
     "shell.execute_reply": "2025-07-20T20:49:19.269696Z"
    },
    "papermill": {
     "duration": 0.02954,
     "end_time": "2025-07-20T20:49:19.271412",
     "exception": false,
     "start_time": "2025-07-20T20:49:19.241872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0306fa89.jpg</td>\n",
       "      <td>Barbari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0345e3ca.jpg</td>\n",
       "      <td>Roman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0551a473.jpg</td>\n",
       "      <td>Sawakni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06e1783d.jpg</td>\n",
       "      <td>Goat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08b9981b.jpg</td>\n",
       "      <td>Barbari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>f3e7b1fe.jpg</td>\n",
       "      <td>Roman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>faadf33d.jpg</td>\n",
       "      <td>Roman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>fbf2e74c.jpg</td>\n",
       "      <td>Sawakni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>ff19c491.jpg</td>\n",
       "      <td>Sawakni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>ffa67e5c.jpg</td>\n",
       "      <td>Barbari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename    label\n",
       "0    0306fa89.jpg  Barbari\n",
       "1    0345e3ca.jpg    Roman\n",
       "2    0551a473.jpg  Sawakni\n",
       "3    06e1783d.jpg     Goat\n",
       "4    08b9981b.jpg  Barbari\n",
       "..            ...      ...\n",
       "139  f3e7b1fe.jpg    Roman\n",
       "140  faadf33d.jpg    Roman\n",
       "141  fbf2e74c.jpg  Sawakni\n",
       "142  ff19c491.jpg  Sawakni\n",
       "143  ffa67e5c.jpg  Barbari\n",
       "\n",
       "[144 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble = best_weight * test_logits_dict[model_names[0]] + (1 - best_weight) * test_logits_dict[model_names[1]]\n",
    "pred = torch.argmax(ensemble, dim=1).numpy()\n",
    "\n",
    "pred_labels = [idx_to_class[i] for i in pred]\n",
    "submission = pd.DataFrame({\n",
    "    'filename': test_filenames,\n",
    "    'label': pred_labels,\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e314f86",
   "metadata": {
    "papermill": {
     "duration": 0.004178,
     "end_time": "2025-07-20T20:49:19.280229",
     "exception": false,
     "start_time": "2025-07-20T20:49:19.276051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 12628243,
     "sourceId": 104830,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 230.212746,
   "end_time": "2025-07-20T20:49:22.473955",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-20T20:45:32.261209",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
